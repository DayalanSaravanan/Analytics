{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 raman supergroup     993700 2020-09-16 10:11 /user/raman/Spark/amusements_in_mathematics.txt\r\n",
      "-rw-r--r--   2 raman supergroup       4351 2020-09-16 10:20 /user/raman/Spark/iris.csv\r\n",
      "-rw-r--r--   2 raman supergroup        539 2020-09-18 12:19 /user/raman/Spark/textfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/raman/Spark/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find length of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfile = sc.textFile(\"/user/raman/Spark/textfile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When a man says, \"I have never solved a puzzle in my life,\" it is',\n",
       " 'difficult to know exactly what he means, for every intelligent',\n",
       " 'individual is doing it every day. The unfortunate inmates of our lunatic',\n",
       " 'asylums are sent there expressly because they cannot solve',\n",
       " 'puzzles--because they have lost their powers of reason. If there were no',\n",
       " 'puzzles to solve, there would be no questions to ask; and if there were',\n",
       " 'no questions to be asked, what a world it would be! We should all be',\n",
       " 'equally omniscient, and conversation would be useless and idle.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfile.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dfile.flatMap(lambda line:line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'a',\n",
       " 'man',\n",
       " 'says,',\n",
       " '\"I',\n",
       " 'have',\n",
       " 'never',\n",
       " 'solved',\n",
       " 'a',\n",
       " 'puzzle',\n",
       " 'in',\n",
       " 'my',\n",
       " 'life,\"',\n",
       " 'it',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'know',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'he',\n",
       " 'means,',\n",
       " 'for',\n",
       " 'every',\n",
       " 'intelligent',\n",
       " 'individual',\n",
       " 'is',\n",
       " 'doing',\n",
       " 'it',\n",
       " 'every',\n",
       " 'day.',\n",
       " 'The',\n",
       " 'unfortunate',\n",
       " 'inmates',\n",
       " 'of',\n",
       " 'our',\n",
       " 'lunatic',\n",
       " 'asylums',\n",
       " 'are',\n",
       " 'sent',\n",
       " 'there',\n",
       " 'expressly',\n",
       " 'because',\n",
       " 'they',\n",
       " 'cannot',\n",
       " 'solve',\n",
       " 'puzzles--because',\n",
       " 'they',\n",
       " 'have',\n",
       " 'lost',\n",
       " 'their',\n",
       " 'powers',\n",
       " 'of',\n",
       " 'reason.',\n",
       " 'If',\n",
       " 'there',\n",
       " 'were',\n",
       " 'no',\n",
       " 'puzzles',\n",
       " 'to',\n",
       " 'solve,',\n",
       " 'there',\n",
       " 'would',\n",
       " 'be',\n",
       " 'no',\n",
       " 'questions',\n",
       " 'to',\n",
       " 'ask;',\n",
       " 'and',\n",
       " 'if',\n",
       " 'there',\n",
       " 'were',\n",
       " 'no',\n",
       " 'questions',\n",
       " 'to',\n",
       " 'be',\n",
       " 'asked,',\n",
       " 'what',\n",
       " 'a',\n",
       " 'world',\n",
       " 'it',\n",
       " 'would',\n",
       " 'be!',\n",
       " 'We',\n",
       " 'should',\n",
       " 'all',\n",
       " 'be',\n",
       " 'equally',\n",
       " 'omniscient,',\n",
       " 'and',\n",
       " 'conversation',\n",
       " 'would',\n",
       " 'be',\n",
       " 'useless',\n",
       " 'and',\n",
       " 'idle.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda word:len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 11,\n",
       " 10,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 11,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 11,\n",
       " 3,\n",
       " 12,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda num:(num, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 1),\n",
       " (1, 1),\n",
       " (3, 1),\n",
       " (5, 1),\n",
       " (2, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (1, 1),\n",
       " (6, 1),\n",
       " (2, 1),\n",
       " (2, 1),\n",
       " (6, 1),\n",
       " (2, 1),\n",
       " (2, 1),\n",
       " (9, 1),\n",
       " (2, 1),\n",
       " (4, 1),\n",
       " (7, 1),\n",
       " (4, 1),\n",
       " (2, 1),\n",
       " (6, 1),\n",
       " (3, 1),\n",
       " (5, 1),\n",
       " (11, 1),\n",
       " (10, 1),\n",
       " (2, 1),\n",
       " (5, 1),\n",
       " (2, 1),\n",
       " (5, 1),\n",
       " (4, 1),\n",
       " (3, 1),\n",
       " (11, 1),\n",
       " (7, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (7, 1),\n",
       " (7, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (9, 1),\n",
       " (7, 1),\n",
       " (4, 1),\n",
       " (6, 1),\n",
       " (5, 1),\n",
       " (16, 1),\n",
       " (4, 1),\n",
       " (4, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (2, 1),\n",
       " (7, 1),\n",
       " (2, 1),\n",
       " (5, 1),\n",
       " (4, 1),\n",
       " (2, 1),\n",
       " (7, 1),\n",
       " (2, 1),\n",
       " (6, 1),\n",
       " (5, 1),\n",
       " (5, 1),\n",
       " (2, 1),\n",
       " (2, 1),\n",
       " (9, 1),\n",
       " (2, 1),\n",
       " (4, 1),\n",
       " (3, 1),\n",
       " (2, 1),\n",
       " (5, 1),\n",
       " (4, 1),\n",
       " (2, 1),\n",
       " (9, 1),\n",
       " (2, 1),\n",
       " (2, 1),\n",
       " (6, 1),\n",
       " (4, 1),\n",
       " (1, 1),\n",
       " (5, 1),\n",
       " (2, 1),\n",
       " (5, 1),\n",
       " (3, 1),\n",
       " (2, 1),\n",
       " (6, 1),\n",
       " (3, 1),\n",
       " (2, 1),\n",
       " (7, 1),\n",
       " (11, 1),\n",
       " (3, 1),\n",
       " (12, 1),\n",
       " (5, 1),\n",
       " (2, 1),\n",
       " (7, 1),\n",
       " (3, 1),\n",
       " (5, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reduceByKey(lambda m,n:m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 14),\n",
       " (2, 25),\n",
       " (6, 9),\n",
       " (10, 1),\n",
       " (16, 1),\n",
       " (12, 1),\n",
       " (1, 3),\n",
       " (3, 10),\n",
       " (5, 16),\n",
       " (9, 4),\n",
       " (7, 9),\n",
       " (11, 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.saveAsTextFile(\"hdfs:///user/raman/Spark/Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - raman supergroup          0 2020-09-18 17:28 /user/raman/Spark/Result\r\n",
      "-rw-r--r--   2 raman supergroup     993700 2020-09-16 10:11 /user/raman/Spark/amusements_in_mathematics.txt\r\n",
      "-rw-r--r--   2 raman supergroup       4351 2020-09-16 10:20 /user/raman/Spark/iris.csv\r\n",
      "-rw-r--r--   2 raman supergroup        539 2020-09-18 12:19 /user/raman/Spark/textfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/raman/Spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "-rw-r--r--   2 raman supergroup          0 2020-09-18 17:28 /user/raman/Spark/Result/_SUCCESS\r\n",
      "-rw-r--r--   2 raman supergroup         47 2020-09-18 17:28 /user/raman/Spark/Result/part-00000\r\n",
      "-rw-r--r--   2 raman supergroup         45 2020-09-18 17:28 /user/raman/Spark/Result/part-00001\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/raman/Spark/Result/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 17:28:33,671 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "(4, 14)\n",
      "(2, 25)\n",
      "(6, 9)\n",
      "(10, 1)\n",
      "(16, 1)\n",
      "(12, 1)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/raman/Spark/Result/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 17:28:36,575 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "(1, 3)\n",
      "(3, 10)\n",
      "(5, 16)\n",
      "(9, 4)\n",
      "(7, 9)\n",
      "(11, 3)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/raman/Spark/Result/part-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a script to find species wise count of sepals in iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - raman supergroup          0 2020-09-18 17:28 /user/raman/Spark/Result\r\n",
      "-rw-r--r--   2 raman supergroup     993700 2020-09-16 10:11 /user/raman/Spark/amusements_in_mathematics.txt\r\n",
      "-rw-r--r--   2 raman supergroup       4351 2020-09-16 10:20 /user/raman/Spark/iris.csv\r\n",
      "-rw-r--r--   2 raman supergroup        539 2020-09-18 12:19 /user/raman/Spark/textfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/raman/Spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", True).csv(\"/user/raman/Spark/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------+------------+-----------+-------+\n",
      "|_c0|Sepal.Length|Sepal.Width|Petal.Length|Petal.Width|Species|\n",
      "+---+------------+-----------+------------+-----------+-------+\n",
      "|  1|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|  2|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|  3|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|  4|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|  5|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|  6|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|  7|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|  8|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|  9|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "| 10|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "+---+------------+-----------+------------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Sepal.Length',\n",
       " 'Sepal.Width',\n",
       " 'Petal.Length',\n",
       " 'Petal.Width',\n",
       " 'Species']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Sepal.Length: string (nullable = true)\n",
      " |-- Sepal.Width: string (nullable = true)\n",
      " |-- Petal.Length: string (nullable = true)\n",
      " |-- Petal.Width: string (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Sepal.Length',\n",
       " 'Sepal.Width',\n",
       " 'Petal.Length',\n",
       " 'Petal.Width',\n",
       " 'Species']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('Sepal.Length', 'string'),\n",
       " ('Sepal.Width', 'string'),\n",
       " ('Petal.Length', 'string'),\n",
       " ('Petal.Width', 'string'),\n",
       " ('Species', 'string')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Petal.Length', 'Petal.Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------+-------+\n",
      "|_c0|Sepal.Length|Sepal.Width|Species|\n",
      "+---+------------+-----------+-------+\n",
      "|  1|         5.1|        3.5| setosa|\n",
      "|  2|         4.9|        3.0| setosa|\n",
      "|  3|         4.7|        3.2| setosa|\n",
      "|  4|         4.6|        3.1| setosa|\n",
      "|  5|         5.0|        3.6| setosa|\n",
      "+---+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------+-------+\n",
      "|_c0|Sepal.Length|Sepal.Width|Species|\n",
      "+---+------------+-----------+-------+\n",
      "|  1|         5.1|        3.5| setosa|\n",
      "|  2|         4.9|        3.0| setosa|\n",
      "|  3|         4.7|        3.2| setosa|\n",
      "|  4|         4.6|        3.1| setosa|\n",
      "|  5|         5.0|        3.6| setosa|\n",
      "+---+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('Sepal.Length', 'Sepal_Length').withColumnRenamed('Sepal.Width', 'Sepal_Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------+-------+\n",
      "|_c0|Sepal_Length|Sepal_Width|Species|\n",
      "+---+------------+-----------+-------+\n",
      "|  1|         5.1|        3.5| setosa|\n",
      "|  2|         4.9|        3.0| setosa|\n",
      "|  3|         4.7|        3.2| setosa|\n",
      "|  4|         4.6|        3.1| setosa|\n",
      "|  5|         5.0|        3.6| setosa|\n",
      "+---+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sepal_Length = df.select(df.Sepal_Length.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Sepal_Length|\n",
      "+------------+\n",
      "|         5.1|\n",
      "|         4.9|\n",
      "|         4.7|\n",
      "|         4.6|\n",
      "|         5.0|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sepal_Length.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sepal_Width = df.select(df.Sepal_Width.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Sepal_Width|\n",
      "+-----------+\n",
      "|        3.5|\n",
      "|        3.0|\n",
      "|        3.2|\n",
      "|        3.1|\n",
      "|        3.6|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Sepal_Width.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Sepal_Length', 'Sepal_Width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|_c0|Species|\n",
      "+---+-------+\n",
      "|  1| setosa|\n",
      "|  2| setosa|\n",
      "|  3| setosa|\n",
      "|  4| setosa|\n",
      "|  5| setosa|\n",
      "+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(Sepal_Length).join(Sepal_Width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------------+-----------+\n",
      "|_c0|Species|Sepal_Length|Sepal_Width|\n",
      "+---+-------+------------+-----------+\n",
      "|  1| setosa|         5.1|        3.5|\n",
      "|  1| setosa|         5.1|        3.0|\n",
      "|  1| setosa|         5.1|        3.2|\n",
      "|  1| setosa|         5.1|        3.1|\n",
      "|  1| setosa|         5.1|        3.6|\n",
      "+---+-------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('Species', 'string'),\n",
       " ('Sepal_Length', 'float'),\n",
       " ('Sepal_Width', 'float')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupby('Species').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|   Species|  count|\n",
      "+----------+-------+\n",
      "| virginica|1125000|\n",
      "|versicolor|1125000|\n",
      "|    setosa|1125000|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of DataFrame[_c0: string, Species: string, Sepal_Length: float, Sepal_Width: float]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
