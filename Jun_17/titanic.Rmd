---
pagetitle: Titanic-Machine Learning from Disaster
author: D.Saravanan
date: 17/06/2020
output: html_notebook
---

```{r setup, include=FALSE}
library(reticulate)
use_python("/home/saran/.envn/dsci/bin/python3", required=TRUE)
knitr::knit_engines$set(python=reticulate::eng_python)
```
#### Titanic: Machine Learning from Disaster
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
#!/usr/bin/env python3
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style('darkgrid')
```
##### read train.csv in df1 
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df1 = pd.read_csv("train.csv")
df1.info()
```
##### read test.csv in df2
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df2 = pd.read_csv("test.csv")
df2.info()
```
##### concatenate dataframes df1 and df2 in df
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df = pd.concat([df1, df2], axis=0)
df.info()
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
Name = df.Name
name = []
for string in Name:
	name.append(string.split(',')[1])

Name = []
for string in name:
	Name.append(string.split('.')[0])

df.Name = Name
df.Name.unique()
```
##### difference between non-null and null values in df
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.count() - df.isnull().sum()
df = df.drop('Cabin', axis=1)
```
##### Correlation Matrix
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.corr()
plt.figure(dpi=90)
sns.heatmap(df.corr(), annot=True)
plt.show()
```
##### No. of null values in df
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.isnull().sum()
```
##### replace null values in Fare with median
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.Fare.median()
df.Fare.fillna(df.Fare.median(), inplace=True)
```
##### replace null values in Embarked with mode (C = Cherbourg, Q = Queenstown, S = Southampton)
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.Embarked.unique()
df.Embarked.mode()
df.Embarked.fillna(df.Embarked.mode()[0], inplace=True)
```

##### to check relation between Age with Pclass, Sex, SibSp, Parch, Embarked
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
#plt.figure(dpi=90)
#sns.boxplot(x=df.Pclass, y=df.Age, palette='Set2')
#plt.show()
#sns.boxplot(x=df.Sex, y=df.Age, palette='Set2')
#plt.show()
#sns.boxplot(x=df.SibSp, y=df.Age, palette='Set2')
#plt.show()
#sns.boxplot(x=df.Parch, y=df.Age, palette='Set2')
#plt.show()
#sns.boxplot(x=df.Embarked, y=df.Age, palette='Set2')
#plt.show()
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.groupby(['Pclass','Name','SibSp','Parch','Embarked']).median()
df['Age'] = df['Age'].fillna(df.groupby(['Pclass','Name','SibSp','Parch','Embarked'])['Age'].transform('median'))
df.isnull().sum()
df['Age'] = df['Age'].fillna(df.groupby(['Pclass','Name','SibSp','Parch'])['Age'].transform('median'))
df.isnull().sum()
df['Age'] = df['Age'].fillna(df.groupby('Pclass')['Age'].transform('median'))
df.isnull().sum()
```

##### Convert string categorical variable to a numeric variable
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
def gender(x):
	if x == 'male': return 1
	else: return 0

df['Sex'] = df['Sex'].apply(gender)

def port(x):
	if x == 'C': return 1
	elif x == 'Q': return 2
	else: return 0

df['Embarked'] = df['Embarked'].apply(port)

def name(x):
	count = 0
	for title in (df.Name.unique()):
		if x == title: return count 
		count = count + 1

df['Name'] = df['Name'].apply(name)
```

```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df.Age.min()
df.Age.max()
df.Fare.min()
df.Fare.max()


plt.figure(dpi=90)
sns.scatterplot(df['Pclass'], df['Fare'])
plt.show()
```



```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
fare1 = df['Fare'][df['Pclass'] == 1]
fare2 = df['Fare'][df['Pclass'] == 2]
fare3 = df['Fare'][df['Pclass'] == 3]

plt.figure(dpi=90)
sns.boxplot(y=fare1)
plt.show()
sns.boxplot(y=fare2)
plt.show()
sns.boxplot(y=fare3)
plt.show()

a1 = fare1.quantile(0.25)
a3 = fare1.quantile(0.75)
iqra = a3-a1

print(((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra))).sum())
fare1 = fare1.mask((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra)))

a1 = fare1.quantile(0.25)
a3 = fare1.quantile(0.75)
iqra = a3-a1

print(((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra))).sum())
fare1 = fare1.mask((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra)))

a1 = fare1.quantile(0.25)
a3 = fare1.quantile(0.75)
iqra = a3-a1

print(((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra))).sum())
fare1 = fare1.mask((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra)))

a1 = fare1.quantile(0.25)
a3 = fare1.quantile(0.75)
iqra = a3-a1

print(((fare1 < (a1-1.5*iqra)) | (fare1 > (a3+1.5*iqra))).sum())

sns.boxplot(y=fare1)
plt.show()


b1 = fare2.quantile(0.25)
b3 = fare2.quantile(0.75)
iqrb = b3-b1

print(((fare2 < (b1-1.5*iqrb)) | (fare2 > (b3+1.5*iqrb))).sum())

c1 = fare3.quantile(0.25)
c3 = fare3.quantile(0.75)
iqrc = c3-c1

print(((fare3 < (c1-1.5*iqrc)) | (fare3 > (c3+1.5*iqrc))).sum())
```


```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
q1 = df['Fare'].quantile(0.25)
q2 = df['Fare'].quantile(0.50)
q3 = df['Fare'].quantile(0.75)

iqr = q3-q1

df['Fare'] = df['Fare'].mask((df['Fare'] < (q1-1.5*iqr)) | (df['Fare'] > (q3+1.5*iqr)))
print(((df['Fare'] < (q1-1.5*iqr)) | (df['Fare'] > (q3+1.5*iqr))).sum())
df.isnull().sum()

df.groupby(['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']).median()
df['Fare'] = df['Fare'].fillna(df.groupby(['Pclass','Embarked'])['Fare'].transform('median'))
df.isnull().sum()
df['Fare'] = df['Fare'].fillna(df.groupby('Embarked')['Fare'].transform('median'))
df.isnull().sum()

plt.figure(dpi=90)
sns.scatterplot(df['Pclass'], df['Fare'])
plt.show()
```






```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
df = df.drop(['PassengerId','Ticket'], axis=1)
df_train = df[pd.notnull(df['Survived'])]
df_test = df[pd.isnull(df['Survived'])]
df_test = df_test.drop('Survived', axis=1)
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
X = df_train.drop('Survived', axis=1)
y = df_train['Survived'].apply(np.int64)
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)
print(X_train.shape, y_train.shape)
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=200)
model.fit(X_train, y_train)
yhat = model.predict(X_test)
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
from sklearn.metrics import confusion_matrix, mean_absolute_error
confusion_matrix(y_test, yhat)
model.score(X_test,y_test)
```
```{python, engine.path="/home/saran/.envn/dsci/bin/python3"}
survived = model.predict(df_test)
dframe = pd.DataFrame({"PassengerId": df2.PassengerId, "Survived": survived})
dframe.head()
dframe.to_csv('submission.csv', index=None, header=True)
```
